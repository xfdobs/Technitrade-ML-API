{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3399d9-52db-46e3-978e-3c418d7121b7",
   "metadata": {},
   "source": [
    "# ML Model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdafc02-deb9-490a-9459-143fd4172b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(\"../marketdata\")\n",
    "import yahoo\n",
    "import alpaca\n",
    "\n",
    "os.chdir(\"../technicals\")\n",
    "import technicals\n",
    "\n",
    "os.chdir(\"../backtests\")\n",
    "import backtest, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb85e0-823f-4873-9c19-b88a1db56efb",
   "metadata": {},
   "source": [
    "### Set model seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a463b4d-8a84-4db5-98b5-5aa86a2100a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The random seed\n",
    "seed = 42\n",
    "\n",
    "# Set seeds\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c961e-8ae6-4532-8c98-53c72500c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tickers = [\"AAPL\"]\n",
    "ohlcv_df = alpaca.ohlcv(test_tickers)\n",
    "# tech_ind = technicals.TechnicalAnalysis(ohlcv_df)\n",
    "# df = tech_ind.get_all_technicals(test_tickers[0], returns_period=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07afaf5a-229e-43aa-bc4b-0baf585a3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_df = ohlcv_df.loc[:,\"AAPL\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b320cd58-6011-47a7-90a2-adafe5c0e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87dc62b-d53a-431f-b935-5ad2fd06b925",
   "metadata": {},
   "source": [
    "---\n",
    "### Set Williams %R params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b855c26-5a10-4ed7-b732-272f957958fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# production Williams %R ranges\n",
    "wr_period = [14]\n",
    "wr_upperband = [-5,-10,-20,-30,-40]\n",
    "wr_lowerband = [-50,-60,-70,-80,-90]\n",
    "\n",
    "print(f\"Williams %R Period : {wr_period}\")\n",
    "print(f\"Williams %R Upper band : {wr_upperband}\")\n",
    "print(f\"Williams %R Lower band : {wr_lowerband}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7787a5a-9409-4098-8d5c-e927754f705d",
   "metadata": {},
   "source": [
    "---\n",
    "### Set broker values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa924fb1-9112-4ab7-931c-b8d34e5c6872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set broker cash, commision\n",
    "start_cash = 1000000.0\n",
    "broker_comm = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b72f1c-d1db-4b10-888e-e3d4e816773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set risk\n",
    "risk = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4ff86-5411-489c-a828-da305b546711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "IST = pytz.timezone('America/New_York')\n",
    "dateformat = \"%Y-%m-%d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9124d1-5371-49da-9662-918973415ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now(IST)\n",
    "end_date = date.strftime(dateformat)\n",
    "start_date = date - timedelta(days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dea47f-d386-44af-9125-4bdb7d6cb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers import wr_cross_strat\n",
    "\n",
    "df = backtest.optimization(strat=wr_cross_strat,\n",
    "                                     ohlcv=ohlcv_df, \n",
    "                                     start_cash=start_cash, \n",
    "                                     broker_comm=broker_comm, \n",
    "                                     risk=risk,\n",
    "                                     period=wr_period,\n",
    "                                     upperband=wr_upperband,\n",
    "                                     lowerband=wr_lowerband,\n",
    "                                     start_date=start_date,\n",
    "                                     end_date=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d7048-29e1-4dc9-b70e-2649c309143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e42f58-6424-46e8-a0e4-11ba5c8845ac",
   "metadata": {},
   "source": [
    "### Train/test plit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c51e1d-05da-44a5-8a0d-c6bb36f26699",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * len(df.index))\n",
    "\n",
    "df_train = df.iloc[: split - 1]\n",
    "df_test = df.iloc[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28000630-bc28-4657-b6a3-fdfee7fd2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331065b-96cf-4284-919c-f267edef19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505e691-f6f6-4915-b48f-4d3e3b06b648",
   "metadata": {},
   "source": [
    "### Train/Validate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1861224-5d9c-4cb2-981c-f9f5977c8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_validate = train_test_split(df_train, train_size=0.8, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d751894-8a0f-48ea-8b1a-55d912f3534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"lagging_returns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc065b-3abd-4379-a19d-cfaaecb01b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature matrix\n",
    "X_train = df_train[np.setdiff1d(df_train.columns, [target])].values\n",
    "X_val = df_val[np.setdiff1d(df_val.columns, [target])].values\n",
    "X_test = df_test[np.setdiff1d(df_test.columns, [target])].values\n",
    "\n",
    "# Get the target vector\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "y_test = df_test[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1daccf1-b07c-4018-b153-9e5768eae0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# The StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Standardize the validation data\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Standardize the test data\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573aa45-0054-4acc-b453-1b73036c8e4a",
   "metadata": {},
   "source": [
    "### ML Model Pipeline Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d75652-dcc9-47e0-94ca-e3750272e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "models = {'lr': LogisticRegression(class_weight='balanced', random_state=seed),\n",
    "          'mlpc': MLPClassifier(early_stopping=True, random_state=seed),\n",
    "          'rfc': RandomForestClassifier(class_weight='balanced', random_state=seed),\n",
    "          'hgbc': HistGradientBoostingClassifier(random_state=seed)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a030dcd-292e-496e-b95a-0b7fdc9a45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline dictionary\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_dict = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipeline_dict[model_name] = Pipeline([('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b820d-a2ed-42c0-911a-ee7f0a117b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "# Code source: https://www.kaggle.com/arushik1994/wids-datathon-logistic-regression\n",
    "\n",
    "def get_train_val_ps(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Get the:\n",
    "    feature matrix and target velctor in the combined training and validation data\n",
    "    target vector in the combined training and validation data\n",
    "    PredefinedSplit\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : the feature matrix in the training data\n",
    "    y_train : the target vector in the training data\n",
    "    X_val : the feature matrix in the validation data\n",
    "    y_val : the target vector in the validation data  \n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "    The feature matrix in the combined training and validation data\n",
    "    The target vector in the combined training and validation data\n",
    "    PredefinedSplit\n",
    "    \"\"\"  \n",
    "\n",
    "    # Combine the feature matrix in the training and validation data\n",
    "    X_train_val = np.vstack((X_train, X_val))\n",
    "\n",
    "    # Combine the target vector in the training and validation data\n",
    "    y_train_val = np.vstack((y_train.reshape(-1, 1), y_val.reshape(-1, 1))).reshape(-1)\n",
    "\n",
    "    # Get the indices of training and validation data\n",
    "    train_val_idxs = np.append(np.full(X_train.shape[0], -1), np.full(X_val.shape[0], 0))\n",
    "\n",
    "    # The PredefinedSplit\n",
    "    ps = PredefinedSplit(train_val_idxs)\n",
    "\n",
    "    return X_train_val, y_train_val, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae738ea2-7462-4aee-a571-c5478f9c1100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used the implementation in pmlm_utilities.ipynb\n",
    "X_train_val, y_train_val, ps = get_train_val_ps(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae48f1-e8a8-4d90-83cb-bdb6e821e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c4bf4-6690-4120-949c-a5213a1d7727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Parameters\n",
    "# The parameter grid of tol\n",
    "tol_grid = [10 ** -5, 10 ** -4, 10 ** -3]\n",
    "\n",
    "# The parameter grid of C\n",
    "C_grid = [0.1, 1, 10]\n",
    "\n",
    "# Update param_grids\n",
    "param_grids['lr'] = [{'model__tol': tol_grid,\n",
    "                      'model__C': C_grid}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392a0ad-afc2-4dc7-bdf4-8c69fcffb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPL Classifier Parameters\n",
    "#The grids for alpha\n",
    "alpha_grids = [10 ** i for i in range(-7, -2)]\n",
    "\n",
    "# The grids for learning_rate_init\n",
    "learning_rate_init_grids = [8 ** i for i in range(-4, -1)]\n",
    "\n",
    "# Update param_grids\n",
    "param_grids['mlpc'] = [{'model__alpha': alpha_grids,\n",
    "                        'model__learning_rate_init': learning_rate_init_grids}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9a087-1229-4ae4-bd6f-ab1c49161020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier Parameters\n",
    "# The grids for min_samples_split\n",
    "min_samples_split_grids = [2, 20, 200]\n",
    "\n",
    "# The grids for min_samples_leaf\n",
    "min_samples_leaf_grids = [1, 20, 200]\n",
    "\n",
    "# Update param_grids\n",
    "param_grids['rfc'] = [{'model__min_samples_split': min_samples_split_grids,\n",
    "                       'model__min_samples_leaf': min_samples_leaf_grids}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbaae38-61a6-473d-9d98-3731ec09c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram Based Gradient Boost Parameters\n",
    "# The grids for learning_rate\n",
    "learning_rate_grids = [10 ** i for i in range(-4, 2)]\n",
    "\n",
    "# The grids for min_samples_leaf\n",
    "min_samples_leaf_grids = [1, 20, 100]\n",
    "\n",
    "# Update param_grids\n",
    "param_grids['hgbc'] = [{'model__learning_rate': learning_rate_grids,\n",
    "                        'model__min_samples_leaf': min_samples_leaf_grids}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f109d20-e437-492c-973a-e4f173988663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# The list of [best_score_, best_params_, best_estimator_] obtained by GridSearchCV\n",
    "best_score_params_estimator_gs = []\n",
    "\n",
    "# For each model\n",
    "for model_name in pipeline_dict.keys():\n",
    "    # GridSearchCV\n",
    "    gs = GridSearchCV(estimator=pipeline_dict[model_name],\n",
    "                      param_grid=param_grids[model_name],\n",
    "                      scoring='f1_macro',\n",
    "                      n_jobs=2,\n",
    "                      cv=ps,\n",
    "                      return_train_score=True)\n",
    "        \n",
    "    # Fit the pipeline\n",
    "    gs = gs.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    # Update best_score_params_estimator_gs\n",
    "    best_score_params_estimator_gs.append([gs.best_score_, gs.best_params_, gs.best_estimator_])\n",
    "    \n",
    "    # Sort cv_results in ascending order of 'rank_test_score' and 'std_test_score'\n",
    "    cv_results = pd.DataFrame.from_dict(gs.cv_results_).sort_values(by=['rank_test_score', 'std_test_score'])\n",
    "    \n",
    "    # Get the important columns in cv_results\n",
    "    important_columns = ['rank_test_score',\n",
    "                         'mean_test_score', \n",
    "                         'std_test_score', \n",
    "                         'mean_train_score', \n",
    "                         'std_train_score',\n",
    "                         'mean_fit_time', \n",
    "                         'std_fit_time',                        \n",
    "                         'mean_score_time', \n",
    "                         'std_score_time']\n",
    "                         # Move the important columns ahead\n",
    "    cv_results = cv_results[important_columns + sorted(list(set(cv_results.columns) - set(important_columns)))]\n",
    "\n",
    "    # Write cv_results file\n",
    "    cv_results.to_csv('test.csv', index=False)\n",
    "\n",
    "# Sort best_score_params_estimator_gs in descending order of the best_score_\n",
    "best_score_params_estimator_gs = sorted(best_score_params_estimator_gs, key=lambda x : x[0], reverse=True)\n",
    "\n",
    "# Print best_score_params_estimator_gs\n",
    "pd.DataFrame(best_score_params_estimator_gs, columns=['best_score', 'best_param', 'best_estimator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb3455-3c52-48de-a92b-6c4119c37700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best_score, best_params and best_estimator obtained by GridSearchCV\n",
    "best_score_gs, best_params_gs, best_estimator_gs = best_score_params_estimator_gs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435c906-8560-4193-80fc-9c40dbd961e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
