{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d610e9f-41c6-44d3-811c-960517a96979",
   "metadata": {},
   "source": [
    "![header](../../img/logo.svg)\n",
    "\n",
    "**NLP Demo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2979dd5b-9709-43df-be2b-42d8ba4baf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc23e594-6771-4c1e-b12a-651b20a1d2d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36aceb1-5f81-4410-9cbd-8934dc66cf57",
   "metadata": {},
   "source": [
    "## Set ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf298ff7-bdbc-4213-8b52-09b5363a006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tickers\n",
    "ticker = 'KO'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d187df25-e33b-451f-b711-f391317303c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2565e1-6c9e-4862-81ec-b4e5c1c6c663",
   "metadata": {},
   "source": [
    "## NLTK sentiment analysis methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24442ed-0450-4b8a-a4a0-c54699ac0e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter debugging mode\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720966fd-ff42-48c0-b0ee-40db3623a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get company name from ticker\n",
    "# Source: https://stackoverflow.com/questions/38967533/retrieve-company-name-with-ticker-symbol-input-yahoo-or-google-api\n",
    "def get_company_name(ticker):\n",
    "    url = \"http://d.yimg.com/autoc.finance.yahoo.com/autoc?query={}&region=1&lang=en\".format(ticker)\n",
    "    result = requests.get(url).json()\n",
    "    for x in result['ResultSet']['Result']:\n",
    "        if x['symbol'] == ticker:\n",
    "            return x['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df3cd72-ba77-4e5e-952d-c395b45b70fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\illya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\illya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\illya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Instantiate the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Create a list of stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "# Expand the default stopwords list if necessary\n",
    "custom_sw = ['char','tec','inc','say','via','bos']\n",
    "\n",
    "def parse_corpus(corpus, datatype = str):\n",
    "    # Tokenize\n",
    "    if datatype == 'news':\n",
    "        tokens = [tokenizer(text) for text in corpus['content']]\n",
    "    elif datatype == 'tweets':\n",
    "        tokens = [tokenizer(text) for text in corpus]\n",
    "\n",
    "    # Flatten the list\n",
    "    flat_tokens = [item for sublist in tokens for item in sublist]\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Number of tokens : {len(flat_tokens)}\")\n",
    "\n",
    "    # String to tokens\n",
    "    str_tokens = ' '.join(flat_tokens)\n",
    "    \n",
    "    return str_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7932ce23-45bb-49dc-b9aa-1c6b680b84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Tokenizez method\n",
    "def tokenizer(text):\n",
    "    \"\"\"Tokenizes text.\"\"\"\n",
    "    \n",
    "    # Remove the punctuation from text\n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "    re_clean = regex.sub('', text)\n",
    "    \n",
    "    # Create a tokenized list of the words\n",
    "    words = word_tokenize(re_clean)\n",
    "    \n",
    "    # Lemmatize words into root words\n",
    "    lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "   \n",
    "    # Convert the words to lowercase\n",
    "    lem_lower = [word.lower() for word in lem]\n",
    "    \n",
    "    # Remove the stop words\n",
    "    tokens_sw = [word for word in lem_lower if word not in sw]\n",
    "    \n",
    "    # Remove custom stop words\n",
    "    tokens_csw = [word for word in tokens_sw if word not in custom_sw]\n",
    "    \n",
    "    # Remove all words less than 3 chars long\n",
    "    tokens = [word for word in tokens_csw if len(word) > 2]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c74fb-7fd3-46d4-bb0e-69d173c62f20",
   "metadata": {},
   "source": [
    "## Google Cloud Sentiment Analysis Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c8058c-f53e-4f33-844e-f50343889aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "# Google Sentiment Analysis requires Google API key\n",
    "# Directions on how to set up the API key: https://cloud.google.com/docs/authentication/getting-started\n",
    "\n",
    "def GetSentimentAnalysisGoogle(text_content):\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '../resources/aic_nlp.json'\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
    "    document = {'content': text_content, 'type_': type_}\n",
    "    encoding_type = language_v1.EncodingType.UTF8\n",
    "    response = client.analyze_sentiment(request={'document': document, 'encoding_type': encoding_type})\n",
    "    return {'score' : response.document_sentiment.score , 'magnitude' : response.document_sentiment.magnitude}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067b694b-9a46-48bc-8254-0696a86c10df",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa330dd-da0f-4fc1-a488-ed5412b7f827",
   "metadata": {},
   "source": [
    "## News Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b541e0-fa67-4a7a-b0c6-965bbcb84b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key Test:\n",
      "NEWSAPI_API_KEY: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# NewsAPI requries an API key\n",
    "# Directions on how to get NewsAPI API key: https://newsapi.org/\n",
    "\n",
    "# load API keys\n",
    "load_dotenv('../resources/api_keys.env')\n",
    "\n",
    "# set NewsAPI API key\n",
    "newsapi_api_key = os.getenv(\"NEWSAPI_API_KEY\")\n",
    "\n",
    "\n",
    "if debug:\n",
    "    print(f\"API Key Test:\")\n",
    "    print(f\"NEWSAPI_API_KEY: {type(newsapi_api_key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd76d3f-7959-4a5a-85df-ca6eb54068e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NewsAPI key\n",
    "from newsapi import NewsApiClient\n",
    "newsapi = NewsApiClient(newsapi_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5943cb3-f7d4-4b18-ad53-0996750c7fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date : 2021-05-15\n",
      "End date : 2021-07-14\n"
     ]
    }
   ],
   "source": [
    "# Set daterange\n",
    "# Set market data date range \n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "end_date  = datetime.now()\n",
    "start_date  = (end_date - timedelta(days=60)).strftime('%Y-%m-%d')\n",
    "end_date = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Start date : {start_date}\")\n",
    "print(f\"End date : {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eefe2f6-dc96-4d52-aa6e-3a4b26f5d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Articles\n",
    "def get_articles(ticker):\n",
    "    company_name = get_company_name(ticker)\n",
    "\n",
    "    article_n = 20 #100 maximum allowed by free NewsAPI account\n",
    "    pages = int(article_n / 20)\n",
    "    btc_news = []\n",
    "\n",
    "    # Get 5 pages of articles (100 articles)\n",
    "    for i in list(range(1,pages+1)):\n",
    "        articles = newsapi.get_everything(q=company_name, language='en', page=i)['articles']\n",
    "        btc_news.append(articles)\n",
    "\n",
    "    corpus = [y for x in btc_news for y in x]\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Total articles about {company_name}: {len(corpus)}\")\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "023aa665-7cb2-464d-ab15-7ab9363648ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles about The Coca-Cola Company: 20\n"
     ]
    }
   ],
   "source": [
    "# Get all articles\n",
    "corpus = pd.DataFrame(get_articles(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22a7f29d-4735-4c10-aecc-ccd8e4ee05f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens : 4659\n"
     ]
    }
   ],
   "source": [
    "# get token string\n",
    "news_str_tokens = parse_corpus(corpus, datatype = 'news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8269130a-d188-41b7-8650-600b738989e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get news sentiment\n",
    "news_sentiment_score = GetSentimentAnalysisGoogle(news_str_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17fc7fb5-9ca5-478b-a3d4-6ba6aea0478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News sentiment score for The Coca-Cola Company = -0.20000000298023224\n"
     ]
    }
   ],
   "source": [
    "print(f\"News sentiment score for {get_company_name(ticker)} = {news_sentiment_score['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0be02b-85d5-49ae-85dd-1d518159488a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bc1890-0e69-4401-9dd2-5ae2ce104902",
   "metadata": {},
   "source": [
    "## Twitter Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85d03880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key Test:\n",
      "TWITTER_API_KEY: <class 'str'>\n",
      "TWITTER_API_SECRET_KEY: <class 'str'>\n",
      "TWITTER_ACCESS_TOKEN: <class 'str'>\n",
      "TWITTER_ACCESS_TOKEN_SECRET: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Twitter API requires API keys\n",
    "# Directions to set up Twitter API keys: https://developer.twitter.com/en/docs/getting-started\n",
    "\n",
    "# load API keys\n",
    "load_dotenv('../resources/api_keys.env')\n",
    "\n",
    "# set NewsAPI API key\n",
    "twitter_api_key = os.getenv(\"TWITTER_API_KEY\")\n",
    "twitter_secret = os.getenv(\"TWITTER_API_SECRET_KEY\")\n",
    "twitter_access_token = os.getenv(\"TWITTER_ACCESS_TOKEN\")\n",
    "twitter_access_token_secret = os.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n",
    "\n",
    "if debug:\n",
    "    print(f\"API Key Test:\")\n",
    "    print(f\"TWITTER_API_KEY: {type(twitter_api_key)}\")\n",
    "    print(f\"TWITTER_API_SECRET_KEY: {type(twitter_secret)}\")\n",
    "    print(f\"TWITTER_ACCESS_TOKEN: {type(twitter_access_token)}\")\n",
    "    print(f\"TWITTER_ACCESS_TOKEN_SECRET: {type(twitter_access_token_secret)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40ec78c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "# Twitter tweepy method\n",
    "def ReturnTwitterData(hashtag,number_tweets):\n",
    "    auth = tweepy.OAuthHandler(twitter_api_key, twitter_secret)\n",
    "    auth.set_access_token(twitter_access_token, twitter_access_token_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    hashtag = hashtag + \" -filter:retweets\"\n",
    "    number_tweets = number_tweets\n",
    "    return tweepy.Cursor(api.search, q=hashtag).items(number_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "701dac7b-baa6-41c9-b568-790005c335fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tweets\n",
    "hashtag = '$'+ticker\n",
    "tweets = ReturnTwitterData(hashtag,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98b3b66f-c2de-4346-8f89-57a9cbb3ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = []\n",
    "for tweet in tweets:\n",
    "    if tweet.lang == \"en\":\n",
    "        text = tweet.text\n",
    "        text = text.split('https://',1)[0]\n",
    "        text = text.split(',',1)[0]\n",
    "        tweet_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26405390-79ae-4e9e-b84c-e7f9c9c1c323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens : 1125\n"
     ]
    }
   ],
   "source": [
    "# get token string\n",
    "tweet_str_tokens = parse_corpus(tweet_list, datatype = 'tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc6178bd-4a72-4d3e-b39f-dd65095388ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get news sentiment\n",
    "tweet_sentiment_score = GetSentimentAnalysisGoogle(tweet_str_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac74d803-b362-4e33-9ca9-f8f5109f3b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter sentiment score for The Coca-Cola Company = -0.4000000059604645\n"
     ]
    }
   ],
   "source": [
    "print(f\"Twitter sentiment score for {get_company_name(ticker)} = {tweet_sentiment_score['score']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
